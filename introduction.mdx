---
title: Introduction
icon: "hand-wave"
---

Quotient is an intelligent observability platform for retrieval-augmented and search-augmented AI applications. It automatically detects problems with hallucinations, context attribution, and context usage. It identifies root causes, and provides visibility -- see what's broken, where it happens, and why.

<CardGroup cols={1}>
  <Card title="Quickstart" icon="play" href="quickstart">
    Get started with Quotient using our quickstart guide.
  </Card>
  {/* <Card title="API Reference" icon="webhook" href="./api-reference">
    Check out the API Reference to see all available endpoints for integrating Quotient into your application.
  </Card> */}
  {/* <Card title="Catch Hallucinations in a AI New Aggregator" icon="user-doctor" href="/examples/job-board">
    Learn how to catch hallucinations in an LLM-powered news application using Quotient
  </Card>
  <Card title="Build a Self-Healing Deep Research Agent" icon="cart-shopping" href="/examples/ecommerce">
    Learn how to build a self-healing deep research agent with Quotient.
  </Card> */}
</CardGroup>

## ðŸ§  Why Quotient AI?

Quotient Detections enables you to automatically catch hallucinations and other reliability issues in your AI outputs as you log user queries, model responses, and documents. You can:

- Track and measure the reliability of your LLM-powered applications
- Identify which retrieved documents contributed to generated responses
- Calculate hallucination rates across different environments
- Flag responses that cannot be traced back to source documents

all with the Quotient SDK in Python or TypeScript in a few lines of code.

![SDK Logging Example](../assets/sdk-logging.png)

## Get in Touch
If you are interested in a self-hosted instance of Quotient, reach out to us by emailing contact@quotientai.co.

To engage with the Quotient community, join our [Discord](https://discord.gg/YeJzANpntv). Follow our [blog](https://www.quotientai.co/blog-index) for insights on AI development and evaluation.


